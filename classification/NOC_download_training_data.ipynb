{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EO4SD SHORELINE CHANGE MAPPING AND FORECASTING\n",
    "\n",
    "This code has been modifed by Carpenter (2020) for the project Earth Observation for Sustainable Development. Below demonstrates an example processing workflow for Benin and Togo's Coastline between 2000-2020.\n",
    "\n",
    "This software is based on scripts and code developed by:\n",
    "* Vos K., Splinter K.D., Harley M.D., Simmons J.A., Turner I.L. (2019). CoastSat: a Google Earth Engine-enabled Python toolkit to extract shorelines from publicly available satellite imagery. Environmental Modelling and Software. 122, 104528. https://doi.org/10.1016/j.envsoft.2019.104528\n",
    "\n",
    "It enables the users to extract time-series of shoreline change over the last 20+ years at their site of interest.\n",
    "There are three main steps:\n",
    "1. Retrieval of median composite satellite images of the region of interest from Google Earth Engine\n",
    "2. Shoreline extraction at sub-pixel resolution\n",
    "\n",
    "## Initial settings\n",
    "\n",
    "Refer to the Set-up and Installation section of the User Handbook for instructions on how to install the Python packages necessary to run the software, including Google Earth Engine Python API. See original methodology via https://github.com/kvos/CoastSat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# coastsat modules\n",
    "sys.path.insert(0, os.pardir)\n",
    "from coastsat import SDS_download, SDS_preprocess, SDS_shoreline, SDS_tools, SDS_transects, \\\n",
    "    NOC_tools, NOC_download\n",
    "\n",
    "# directory where the data will be accessed and stored\n",
    "dataPartition = 'c:\\\\data\\\\coastsat'\n",
    "country = 'STV'\n",
    "base_filepath = os.path.join(dataPartition, country, 'classification')  \n",
    "sites_dir_path = os.path.join(os.path.join(base_filepath, 'training_sites'))\n",
    "training_dir_path = os.path.join(os.path.join(base_filepath, 'data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download images\n",
    "For each site on which you want to train the classifier, save a .kml file with the region of interest (5 vertices clockwise, first and last points are the same, can be created from Google myMaps) in the folder \\training_sites.\n",
    "\n",
    "You only need a few images (~10) to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_sites = os.listdir(sites_dir_path)\n",
    "\n",
    "for roi_kml in roi_sites:\n",
    "    \n",
    "    sitename = roi_kml[:roi_kml.find('.')] \n",
    "    \n",
    "    print('***********************************************************')\n",
    "    print(f'processing roi: {sitename}')\n",
    "    print()\n",
    "    \n",
    "    kml_filepath = os.path.join(sites_dir_path, roi_kml)\n",
    "    kml_polygon = NOC_tools.polygon_from_kml(kml_filepath)\n",
    "    roi_polygon = SDS_tools.smallest_rectangle(kml_polygon)\n",
    "\n",
    "        \n",
    "    all_dates = [['2020-01-01', '2020-01-31'],['2020-02-01', '2020-02-28'],['2020-03-01', '2020-03-31'],\n",
    "                 ['2020-04-01', '2020-04-30'],['2020-05-01', '2020-05-31'],['2020-06-01', '2020-06-30'],\n",
    "                 ['2020-07-01', '2020-07-31'],['2020-08-01', '2020-08-31'],['2020-09-01', '2020-09-30'],\n",
    "                 ['2020-10-01', '2020-10-31'],['2020-11-01', '2020-11-30'],['2020-12-01', '2020-12-31']]\n",
    "\n",
    "    all_dates = [['2019-01-01', '2020-12-31']]\n",
    "                  \n",
    "    for date_pair in all_dates:\n",
    "        \n",
    "        print(f'    from {date_pair[0]} to {date_pair[1]}')\n",
    "        \n",
    "        # put all the inputs into a dictionnary\n",
    "        inputs = {'polygon': roi_polygon, 'dates': date_pair, 'sat_list': ['S2'],\n",
    "                  'sitename': sitename, 'filepath': training_dir_path, 'include_T2': False}\n",
    "\n",
    "        metadata = NOC_download.retrieve_training_images(inputs)\n",
    "\n",
    "print('***********************************************************')\n",
    "print(f'finished ...')\n",
    "print('***********************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
